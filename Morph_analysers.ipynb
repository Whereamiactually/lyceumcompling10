{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2fLQ0pw8gca8HTHFhUW3U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whereamiactually/lyceumcompling10/blob/main/Morph_analysers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализаторы\n",
        "\n",
        "*   **PyMorphy2** - морфологический анализатор для русского и украинского языков, при работе использует словарь и корпус текстов [OpenCorpora](https://opencorpora.org/), но если слово незнакомое, он строит гипотезу. К сожалению, PyMorphy2 не учитывает контекст, а работает с отдельными словами. В OpenCorpora содержится 391842 лемм (5141279 форм).\n",
        "*   **MyStem** - морфологический анализатор для русского, польско и английского языков ([разработка Яндекс](https://yandex.ru/dev/mystem/)). При работе учитывает контекст, также умеет строить гипотезы. Более высокая точность, чем у PyMorphy2.\n",
        "*   **SpaCy** - морфологический анализатор (а еще он умеет работать с именованными сущностями, синтаксическими зависимостями, векторным представлением слов и пр.), который работает с 25+ языками ([сайт проекта](https://spacy.io/)). [Здесь](https://spacy.io/usage/linguistic-features) ссылка на все его NLP функции.\n",
        "\n"
      ],
      "metadata": {
        "id": "tgmYOdzWhImj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyMorphy2"
      ],
      "metadata": {
        "id": "9iEFk0ZtjxA4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lIyOtUVIuOm",
        "outputId": "30466bbf-d8a9-444b-b00d-e79f2ee69ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=0009485e5eac080c92154a4a0ab6318f002c2d232812888c34da83de0daff929\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "3SKlOWAIimiJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import string"
      ],
      "metadata": {
        "id": "KKSsUMX5kZM5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Здесь](https://pymorphy2.readthedocs.io/en/stable/) лежит вся документация по работе с PyMorphy2, [здесь](https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html) - обозначения для частей речи и некоторых других морфологических характеристик слова (падеж, число, род) и то, как их вынуть из морф. разбора, а [здесь](https://opencorpora.org/dict.php?act=gram) - список всех морфологических характеристик слова.\n",
        "\n",
        "* `word` содержит полученное анализатором слово,\n",
        "* `tag` содержит морф. характеристики слова,\n",
        "* `normal_form` содержит лемму (начальную форму) слова,\n",
        "* `score` содержит вероятность именно этого морф. разбора для заданного слова (определяется по частоте встречаемости слова с такими морф. характеристиками),\n",
        "* `methods_stack` содержит информацию о том, с помощью чего было проанализировано это слово. Если слово нашлось в словаре, то у этого атрибута будет значение `DictionaryAnalyzer()` (**\"словарный анализатор\"**), если не нашлось, то анализатор может попытаться почленить слово и выделить в нем знакомый для него суффикс, тогда у этого атрибута будет значение `KnownSuffixAnalyzer()` (**\"анализатор известных суффиксов\"**). Если же ни слово, ни суффикс не будут знакомы анализатору, то у этого атрибута будет значение `FakeDictionary()` (**\"фейковый словарь\"**)."
      ],
      "metadata": {
        "id": "i5Rm0QLzyXJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('яблок')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkHuMmvpgz7",
        "outputId": "7254722c-ae92-4c45-f1eb-46857f021171"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='яблок', tag=OpencorporaTag('NOUN,inan,neut plur,gent'), normal_form='яблоко', score=1.0, methods_stack=((DictionaryAnalyzer(), 'яблок', 583, 7),))]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('яблоков')"
      ],
      "metadata": {
        "id": "FHfjBA8gyTim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('стол')"
      ],
      "metadata": {
        "id": "PbKG4_X5ppgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('финтифлюшки')"
      ],
      "metadata": {
        "id": "1AiXbd24o-1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('водомотодельтаплан')"
      ],
      "metadata": {
        "id": "NqRHPTCK36Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('бутявковедами')"
      ],
      "metadata": {
        "id": "Fkfzzbcg0NWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Регистр не играет роли."
      ],
      "metadata": {
        "id": "8NwTXkCP3cuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('КрАсОтА')"
      ],
      "metadata": {
        "id": "qR1aqSYz3egN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если мы хотим морфологический разбор для всех слов в предложении, то нам надо пройтись по каждому слову по отдельности."
      ],
      "metadata": {
        "id": "6g-cSLqD4IuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Я лгал; но мне хотелось его побесить. У меня врожденная страсть противоречить.\"\n",
        "for word in sentence.split():\n",
        "  print(word.strip(string.punctuation))\n",
        "  pprint(morph.parse(word.strip(string.punctuation)))"
      ],
      "metadata": {
        "id": "ySPX-20olFKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strange_sentence = \"Глокая куздра штеко будланула бокра и курдячит бокрёнка.\"\n",
        "for word in strange_sentence.split():\n",
        "  print(word.strip(string.punctuation))\n",
        "  pprint(morph.parse(word.strip(string.punctuation)))"
      ],
      "metadata": {
        "id": "p5-13OH0jvgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можем отдельно вытащить словоформу, ее разбор и лемму."
      ],
      "metadata": {
        "id": "Ebap9C565KkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence.split():\n",
        "  parser = morph.parse(word.strip(string.punctuation))[0] # самый первый разбор самый вероятный\n",
        "  print(word.strip(string.punctuation), ':', parser.normal_form, ':', parser.tag, sep = ' ')"
      ],
      "metadata": {
        "id": "7gp395UxnAE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in strange_sentence.split():\n",
        "  parser = morph.parse(word.strip(string.punctuation))[0]\n",
        "  print(word.strip(string.punctuation), ':', parser.normal_form, ':', parser.tag, sep = ' ')"
      ],
      "metadata": {
        "id": "ksq3O8TKowIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем также склонять или спрягать разные слова (даже если они анализатору неизвестны)."
      ],
      "metadata": {
        "id": "4-erVaG4o2A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kvakat = morph.parse('квакала')[0]\n",
        "print(kvakat.inflect({'plur'}))\n",
        "print(kvakat.inflect({'plur', 'pres'}))\n",
        "print(kvakat.inflect({'pres'}))\n",
        "print(kvakat.inflect({'past', 'masc'}))"
      ],
      "metadata": {
        "id": "YyKAiVgL51Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ship = morph.parse('корабль')[0]\n",
        "print(ship)\n",
        "print(ship.inflect({'plur','ablt'}))\n",
        "print(ship.inflect({'plur','nomn'}))"
      ],
      "metadata": {
        "id": "3gRUuNrr7YUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kurd = morph.parse('курдячит')[0]\n",
        "print(kurd.inflect({'plur'}))\n",
        "print(kurd.inflect({'plur', 'past'}))\n",
        "print(kurd.inflect({'past'}))\n",
        "print(kurd.inflect({'past', 'femn'}))"
      ],
      "metadata": {
        "id": "GwlBpLCOo1dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можем попросить выдать нам все возможные формы лексемы."
      ],
      "metadata": {
        "id": "wB1nQYMHp29L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lexeme in kurd.lexeme:\n",
        "  print(lexeme.word)"
      ],
      "metadata": {
        "id": "eA5BDWaIprGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также есть очень удобная функция, которая ставит слово в нужную форму в зависимости от числительного."
      ],
      "metadata": {
        "id": "UusttAfnp7IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apple = morph.parse('яблоко')[0]\n",
        "print(apple.make_agree_with_number(1).word)\n",
        "print(apple.make_agree_with_number(3).word)\n",
        "print(apple.make_agree_with_number(4).word)\n",
        "print(apple.make_agree_with_number(5).word)\n",
        "print(apple.make_agree_with_number(21).word)"
      ],
      "metadata": {
        "id": "AQ1piFT9qWyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем проверять, есть ли в теге нужная нам граммема."
      ],
      "metadata": {
        "id": "KL6tcq-e8bUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('VERB' in apple.tag) # является ли слово глаголом\n",
        "print('NOUN' in apple.tag) # является ли слово существительным\n",
        "print({'plur', 'past'} in apple.tag) # стоит ли слово в прошедшем времени и множественном числе\n",
        "print({'NOUN', 'sing'} in apple.tag) # является ли слово существительным единственного числа"
      ],
      "metadata": {
        "id": "apGrlawo8ikK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crash = morph.parse('сломал')[0]\n",
        "crash"
      ],
      "metadata": {
        "id": "HJRtUs2o9lOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем вытягивать отдельные морфологические характеристики слова."
      ],
      "metadata": {
        "id": "RJQQ0nI6_Bjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Часть речь:', crash.tag.POS) # часть речи\n",
        "print('Одушевленность:', apple.tag.animacy) # одушевленность\n",
        "print('Вид:', crash.tag.aspect) # вид (соверешенный, несовершенный)\n",
        "print('Падеж:', apple.tag.case) # падеж\n",
        "print('Род:', apple.tag.gender) # род (мужской, женский, средний)\n",
        "print('Включенность говорящего в действие:', crash.tag.involvement) # включенность говорящего в действие\n",
        "print('Наклонение:', crash.tag.mood) # наклонение (повелительное, изъявительное)\n",
        "print('Число:', apple.tag.number) # число (единственное, множественное)\n",
        "print('Лицо:', crash.tag.person) # лицо (1, 2, 3)\n",
        "print('Время:', crash.tag.tense) # время (настоящее, прошедшее, будущее)\n",
        "print('Переходность:', crash.tag.transitivity) # переходность (переходный, непереходный)\n",
        "print('Залог:', crash.tag.voice) # залог (действительный, страдательный)"
      ],
      "metadata": {
        "id": "muDyPlOM9QLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MyStem"
      ],
      "metadata": {
        "id": "1KCcTR99pEhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "m = Mystem()"
      ],
      "metadata": {
        "id": "A4dwQNDXrCgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем лемматизировать предложение."
      ],
      "metadata": {
        "id": "qvgWlOWO_rQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = m.lemmatize(sentence)\n",
        "lemmas"
      ],
      "metadata": {
        "id": "Fm_OlaODrKb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В отличие от PyMorphy2, MyStem может сделать морфологические разбор целого предложения, ему даже *нужно* целое предложение, чтобы сделать разбор.\n",
        "\n",
        "MyStem работает более точно, потому что он ориентируется на контекст. Кроме того, как можно заметить, он предлагает лишь один разбор для каждого слова (что логично, так как он ориентируется на контекст).\n",
        "\n",
        "[Здесь](https://yandex.ru/dev/mystem/doc/ru/grammemes-values) лежит список использующихся условных сокращений для разных морфологических характеристик слов.\n",
        "\n",
        "* `gr` содержит морф. разбор,\n",
        "* `lex` содержит лемму слова,\n",
        "* `wt` содержит вероятность именно такого разбора в данном контексте."
      ],
      "metadata": {
        "id": "yRtnnP91Apt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = m.analyze(sentence)\n",
        "pprint(analysis)"
      ],
      "metadata": {
        "id": "YxUoEaDvriSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "До знака равенства находятся \"врожденные характеристики\" слова. Например, род для существительного - это неизменяемая врожденная характериситка, тогда как род для прилагательного - изменяемая (соответственно, находится после занка равенства)."
      ],
      "metadata": {
        "id": "UsB84Q2iC2_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in analysis:\n",
        "    if 'analysis' in word:\n",
        "        gr = word['analysis'][0]['gr'] # берем морф. разбор из 'analysis'\n",
        "        pos = gr.split('=')[0].split(',')[0] # берем первый элемент списка (часть речи)\n",
        "        print(word['text'], pos)"
      ],
      "metadata": {
        "id": "PM_iPFj2rryy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если предложение состоит полностью из неизвестных слов, от качество анализа заметно хуже. Оно и не мудрено. `bastard` означает, что слово не нашлось в словаре."
      ],
      "metadata": {
        "id": "ik51YCUUEKqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = m.analyze(strange_sentence)\n",
        "pprint(analysis)"
      ],
      "metadata": {
        "id": "c4gvFuUasZfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = m.analyze('Кажется, Порфирий Петрович шлёпнулся на землю около озера Байкал.')\n",
        "pprint(analysis)"
      ],
      "metadata": {
        "id": "fFN-HLCHEfUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SpaCy\n",
        "\n",
        "Мы уже смотрели на эту библиотеку при знакомстве с распознаванием именованных сущностей. Теперь посмотрим, что она умеет еще."
      ],
      "metadata": {
        "id": "Q1kZDX_auNEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp_en = spacy.load(\"en_core_web_sm\") # \"sm\" означает маленький"
      ],
      "metadata": {
        "id": "MfNPf5mZI8bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_en = \"Colorless green ideas sleep furiously.\"\n",
        "doc = nlp_en(text_en)\n",
        "for token in doc:\n",
        "   print([token.lemma_, token.pos_, token.morph])"
      ],
      "metadata": {
        "id": "9Qp_fyx9uUkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Про каждое слово мы можем узнать очень много информации:\n",
        "\n",
        "* `text`: исходное слово,\n",
        "* `lemma`: лемма,\n",
        "* `POS`: \"простая\" часть речи (местоимение, глагол, ...),\n",
        "* `tag`: \"уточненная\" часть речи (деепричастие, причастие, ...),\n",
        "* `dep`: синтаксические связи между словами в предложении,\n",
        "* `shape`: вид слова (заглавные буквы, пунктуация, цифры),\n",
        "* `is alpha`: состоит ли слово только из букв,\n",
        "* `is stop`: является ли слово стоп-словом."
      ],
      "metadata": {
        "id": "Zxv6h835HgRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_sm # нужно загрузить для работы с языками, отличными от английского"
      ],
      "metadata": {
        "id": "69gm9n3lG066"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_rus = spacy.load(\"ru_core_news_sm\")"
      ],
      "metadata": {
        "id": "gDWLVg1JJAB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_rus(sentence)\n",
        "for token in doc:\n",
        "  print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "        token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "id": "xBojCVXFGbI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_rus = \"Делая это задание, я НиЧеГо не п0нимаю.\"\n",
        "doc = nlp_rus(text_rus)\n",
        "for token in doc:\n",
        "  print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "        token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "id": "2SeJeTNdI0bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, разбор для русского языка более богатый, что связано с морфологическими особенностями английского языка.\n",
        "\n",
        "SpaCy также, помимо всего прочего, может делить на предложения."
      ],
      "metadata": {
        "id": "9R3O5ZnrHMCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_rus(\"Это предложение. И это предложение!!!\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ],
      "metadata": {
        "id": "k1ohtNLXKylv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из токенов он может собирать обратно целое предложение.\n"
      ],
      "metadata": {
        "id": "BSjsb6wiLjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"До:\", [token.text for token in doc])\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(doc[3:8])\n",
        "print(\"После:\", [token.text for token in doc])"
      ],
      "metadata": {
        "id": "3nMn1UVPLC_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ещё крутая функция: можно сравнивать предложения или тексты между собой."
      ],
      "metadata": {
        "id": "tC9VUneLw9wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_md # надо загрузить корпус побольше"
      ],
      "metadata": {
        "id": "ERSLQIAxNfC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_rus_md = spacy.load(\"ru_core_news_md\") # чтобы сравнивать тексты, нам нужны вектора слов, а они есть только в среднем или крупном корпусе"
      ],
      "metadata": {
        "id": "WdFKEWrZMs3B"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_lg # еще побольше (весит аж почти 500 мегабайт)"
      ],
      "metadata": {
        "id": "Ch6Rsvm-Ny_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_rus_lg = spacy.load(\"ru_core_news_lg\")"
      ],
      "metadata": {
        "id": "QSoBhVRZN5JV"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_doc = nlp_rus_lg(\"Я очень хочу сходить в Большой Театр на оперу, только вот не знаю, позволит ли мне работа.\")\n",
        "main_doc = nlp_rus_lg(\"В Большом Театре в следующие выходные будет грандиозное событие - будут выступать оперные певцы из Италии.\")\n",
        "print(main_doc.similarity(search_doc))"
      ],
      "metadata": {
        "id": "AvaVxGEtxOQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для более точного сравнения нам мешают стоп-слова. Уберем их. А так как каждое слова размечается по этому признаку, то убрать их будет довольно легко.\n",
        "\n",
        "Добавляем слово в список, только если оно не является стоп-словом. Затем из списка снова делаем строку с помощью метода `' '.join()`. Затем снова парсим получившуюся строку без стоп-слов."
      ],
      "metadata": {
        "id": "urHuL3eIO3lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_doc_no_stop_words = nlp_rus_lg(' '.join([str(t) for t in search_doc if not t.is_stop]))\n",
        "main_doc_no_stop_words = nlp_rus_lg(' '.join([str(t) for t in main_doc if not t.is_stop]))\n",
        "\n",
        "print(search_doc_no_stop_words.similarity(main_doc_no_stop_words))"
      ],
      "metadata": {
        "id": "v4oY7ggQxCGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "У SpaCy есть готовый pipeline (цепочка действий (функций) для получения конкретного результата) для тренировки вашего собственного анализатора на ваших размеченных данных (но, кажется, доступ там платный). Для этого нужно очень много размеченного материала, но можно попробовать сделать для языков с малым количеством носителей."
      ],
      "metadata": {
        "id": "NG44d_4VyoxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашка\n",
        "\n",
        "Можете делать домашку, где хотите. Её можно прислать через эту [форму](https://forms.gle/Mwvg8BGANvNYePnq5) в формате .py или .ipynb (либо ссылкой на тетрадку, но тогда не забудьте дать доступ). Дедлайн домашки: 20.11.2023 23:59.\n",
        "\n",
        "### Неправильный морфологический разбор\n",
        "\n",
        "Придумайте такое предложение, для которого PyMorphy2 делает неправильный разбор, и напишите, почему он делает такую ошибку.\n",
        "\n"
      ],
      "metadata": {
        "id": "O9Qrp0l-TsCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ваш код здесь"
      ],
      "metadata": {
        "id": "jGRhr3Csbezt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исправляет ли эту ошибку MyStem? Почему?"
      ],
      "metadata": {
        "id": "2RGeZRo1b7R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ваш код здесь"
      ],
      "metadata": {
        "id": "Qr-JU9Z8b-Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите часть речь для каждого слова в этом предложении, также выведите, является ли каждое слово стоп-словом."
      ],
      "metadata": {
        "id": "nuLpbHXUcG5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ваш код здесь"
      ],
      "metadata": {
        "id": "gUONt3J6chKA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}